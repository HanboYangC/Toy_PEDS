/blue/guo/yangh/Toy_PEDS/sh
c0304a-s10.ufhpc
Tue Aug 20 02:22:56 EDT 2024
device:cuda
Generating data:   0%|                                                                                                                                                              | 0/10000 [00:00<?, ?it/s]Generating data:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 9380/10000 [00:00<00:00, 74932.38it/s]Generating data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 76142.67it/s]
Testing w=0.0
Training and validation data loaded successfully on cuda.
Epoch [1/200], New best model saved with Val Loss: 0.005259453610051423
Epoch [1/200], Train Loss: 0.0037943027193912053, Val Loss: 0.005259453610051423
Epoch [2/200], Train Loss: 0.00379807592517781, Val Loss: 0.005259453610051423
Epoch [3/200], Train Loss: 0.0038017044849270446, Val Loss: 0.005259453610051423
Epoch [4/200], Train Loss: 0.0037969123804941773, Val Loss: 0.005259453610051423
Epoch [5/200], Train Loss: 0.003810498101467436, Val Loss: 0.005259453610051423
Epoch [6/200], Train Loss: 0.0037917027101767335, Val Loss: 0.005259453610051423
Epoch [7/200], Train Loss: 0.0037958046675405717, Val Loss: 0.005259453610051423
Epoch [8/200], Train Loss: 0.0037863112943754954, Val Loss: 0.005259453610051423
Epoch [9/200], Train Loss: 0.003784249753648923, Val Loss: 0.005259453610051423
Epoch [10/200], Train Loss: 0.003795033775862645, Val Loss: 0.005259453610051423
Epoch [11/200], Train Loss: 0.0037971194251440465, Val Loss: 0.005259453610051423
Epoch [12/200], Train Loss: 0.0038085789525542746, Val Loss: 0.005259453610051423
Epoch [13/200], Train Loss: 0.0037904676176946273, Val Loss: 0.005259453610051423
Epoch [14/200], Train Loss: 0.003792863109000874, Val Loss: 0.005259453610051423
Epoch [15/200], Train Loss: 0.0038013971008529716, Val Loss: 0.005259453610051423
Epoch [16/200], Train Loss: 0.003790366823192347, Val Loss: 0.005259453610051423
Epoch [17/200], Train Loss: 0.003793559926138683, Val Loss: 0.005259453610051423
Epoch [18/200], Train Loss: 0.0038012755262157457, Val Loss: 0.005259453610051423
Epoch [19/200], Train Loss: 0.003798326683781025, Val Loss: 0.005259453610051423
Epoch [20/200], Train Loss: 0.0037871780805289745, Val Loss: 0.005259453610051423
Epoch [21/200], Train Loss: 0.0037989734291014347, Val Loss: 0.005259453610051423
Epoch [22/200], Train Loss: 0.0037943171443079004, Val Loss: 0.005259453610051423
Epoch [23/200], Train Loss: 0.003795950123193589, Val Loss: 0.005259453610051423
Epoch [24/200], Train Loss: 0.0038154851116070695, Val Loss: 0.005259453610051423
Epoch [25/200], Train Loss: 0.003792124181266197, Val Loss: 0.005259453610051423
Epoch [26/200], Train Loss: 0.003787701923019168, Val Loss: 0.005259453610051423
Epoch [27/200], Train Loss: 0.0037902794058688664, Val Loss: 0.005259453610051423
Epoch [28/200], Train Loss: 0.0037978798764842477, Val Loss: 0.005259453610051423
Epoch [29/200], Train Loss: 0.0038047822044146333, Val Loss: 0.005259453610051423
Epoch [30/200], Train Loss: 0.0038064230466261506, Val Loss: 0.005259453610051423
Epoch [31/200], Train Loss: 0.003799433491870084, Val Loss: 0.005259453610051423
Epoch [32/200], Train Loss: 0.0038123179057782345, Val Loss: 0.005259453610051423
Epoch [33/200], Train Loss: 0.003792306064331735, Val Loss: 0.005259453610051423
Epoch [34/200], Train Loss: 0.0038075455443256283, Val Loss: 0.005259453610051423
Epoch [35/200], Train Loss: 0.0037957062542607837, Val Loss: 0.005259453610051423
Epoch [36/200], Train Loss: 0.003786272919652137, Val Loss: 0.005259453610051423
Epoch [37/200], Train Loss: 0.0037953301692720165, Val Loss: 0.005259453610051423
Epoch [38/200], Train Loss: 0.003803384601434862, Val Loss: 0.005259453610051423
Epoch [39/200], Train Loss: 0.0037874193142422223, Val Loss: 0.005259453610051423
Epoch [40/200], Train Loss: 0.0037930210078643127, Val Loss: 0.005259453610051423
Epoch [41/200], Train Loss: 0.0038009722272611475, Val Loss: 0.005259453610051423
Epoch [42/200], Train Loss: 0.003790944973430173, Val Loss: 0.005259453610051423
Epoch [43/200], Train Loss: 0.003788351192435419, Val Loss: 0.005259453610051423
Epoch [44/200], Train Loss: 0.003780783582690426, Val Loss: 0.005259453610051423
Epoch [45/200], Train Loss: 0.003798569309186529, Val Loss: 0.005259453610051423
Epoch [46/200], Train Loss: 0.003785227658227086, Val Loss: 0.005259453610051423
Epoch [47/200], Train Loss: 0.0037931503347036514, Val Loss: 0.005259453610051423
Epoch [48/200], Train Loss: 0.003798432320102372, Val Loss: 0.005259453610051423
Epoch [49/200], Train Loss: 0.003793451850387183, Val Loss: 0.005259453610051423
Epoch [50/200], Train Loss: 0.003794602319513532, Val Loss: 0.005259453610051423
Epoch [51/200], Train Loss: 0.0037963638103313065, Val Loss: 0.005259453610051423
Epoch [52/200], Train Loss: 0.0037906167033890433, Val Loss: 0.005259453610051423
Epoch [53/200], Train Loss: 0.0037892947015775876, Val Loss: 0.005259453610051423
Epoch [54/200], Train Loss: 0.0037934319222007284, Val Loss: 0.005259453610051423
Epoch [55/200], Train Loss: 0.0037964963756332345, Val Loss: 0.005259453610051423
Epoch [56/200], Train Loss: 0.003793837735429406, Val Loss: 0.005259453610051423
Epoch [57/200], Train Loss: 0.0037920236407609827, Val Loss: 0.005259453610051423
Epoch [58/200], Train Loss: 0.0038037146229974246, Val Loss: 0.005259453610051423
Epoch [59/200], Train Loss: 0.003786270490805195, Val Loss: 0.005259453610051423
Epoch [60/200], Train Loss: 0.0037935434163294053, Val Loss: 0.005259453610051423
Epoch [61/200], Train Loss: 0.00379250445720655, Val Loss: 0.005259453610051423
Epoch [62/200], Train Loss: 0.0037857766093855553, Val Loss: 0.005259453610051423
Epoch [63/200], Train Loss: 0.0038007616901516235, Val Loss: 0.005259453610051423
Epoch [64/200], Train Loss: 0.0037849419538609004, Val Loss: 0.005259453610051423
Epoch [65/200], Train Loss: 0.003798710970758376, Val Loss: 0.005259453610051423
Epoch [66/200], Train Loss: 0.003790621010755951, Val Loss: 0.005259453610051423
Epoch [67/200], Train Loss: 0.003794140902093866, Val Loss: 0.005259453610051423
Epoch [68/200], Train Loss: 0.0037860678170215, Val Loss: 0.005259453610051423
Epoch [69/200], Train Loss: 0.0037921051685275, Val Loss: 0.005259453610051423
Epoch [70/200], Train Loss: 0.0038022889163006435, Val Loss: 0.005259453610051423
Epoch [71/200], Train Loss: 0.0038001071873374963, Val Loss: 0.005259453610051423
Epoch [72/200], Train Loss: 0.003818180126307363, Val Loss: 0.005259453610051423
Epoch [73/200], Train Loss: 0.003791134084828875, Val Loss: 0.005259453610051423
Epoch [74/200], Train Loss: 0.003798901357434013, Val Loss: 0.005259453610051423
Epoch [75/200], Train Loss: 0.003801253529011526, Val Loss: 0.005259453610051423
Epoch [76/200], Train Loss: 0.003796811236745932, Val Loss: 0.005259453610051423
Epoch [77/200], Train Loss: 0.003787388157268817, Val Loss: 0.005259453610051423
Epoch [78/200], Train Loss: 0.00380296442149715, Val Loss: 0.005259453610051423
Epoch [79/200], Train Loss: 0.0037920782025056806, Val Loss: 0.005259453610051423
Epoch [80/200], Train Loss: 0.003798276080157269, Val Loss: 0.005259453610051423
Epoch [81/200], Train Loss: 0.003811484255658632, Val Loss: 0.005259453610051423
Epoch [82/200], Train Loss: 0.003792959254827689, Val Loss: 0.005259453610051423
Epoch [83/200], Train Loss: 0.0037922413638708267, Val Loss: 0.005259453610051423
Epoch [84/200], Train Loss: 0.003788106884299354, Val Loss: 0.005259453610051423
Epoch [85/200], Train Loss: 0.003788000702942637, Val Loss: 0.005259453610051423
Epoch [86/200], Train Loss: 0.0037974278516644104, Val Loss: 0.005259453610051423
Epoch [87/200], Train Loss: 0.003791375339708545, Val Loss: 0.005259453610051423
Epoch [88/200], Train Loss: 0.0037856351224366913, Val Loss: 0.005259453610051423
Epoch [89/200], Train Loss: 0.0037935614183714442, Val Loss: 0.005259453610051423
Epoch [90/200], Train Loss: 0.0037870896578004413, Val Loss: 0.005259453610051423
Epoch [91/200], Train Loss: 0.0037909435129470444, Val Loss: 0.005259453610051423
Epoch [92/200], Train Loss: 0.0037928351349281993, Val Loss: 0.005259453610051423
Epoch [93/200], Train Loss: 0.0038053097351538863, Val Loss: 0.005259453610051423
Epoch [94/200], Train Loss: 0.0037951540328900924, Val Loss: 0.005259453610051423
Epoch [95/200], Train Loss: 0.003791252309879796, Val Loss: 0.005259453610051423
Epoch [96/200], Train Loss: 0.003787267794409259, Val Loss: 0.005259453610051423
Epoch [97/200], Train Loss: 0.0037897708084942265, Val Loss: 0.005259453610051423
Epoch [98/200], Train Loss: 0.0037976497921838677, Val Loss: 0.005259453610051423
Epoch [99/200], Train Loss: 0.003792704739184542, Val Loss: 0.005259453610051423
Epoch [100/200], Train Loss: 0.0037907059621912513, Val Loss: 0.005259453610051423
Epoch [101/200], Train Loss: 0.0037960682529956102, Val Loss: 0.005259453610051423
Epoch [102/200], Train Loss: 0.003819116295992651, Val Loss: 0.005259453610051423
Epoch [103/200], Train Loss: 0.003782255495686761, Val Loss: 0.005259453610051423
Epoch [104/200], Train Loss: 0.0037917005935345183, Val Loss: 0.005259453610051423
Epoch [105/200], Train Loss: 0.003791019426320087, Val Loss: 0.005259453610051423
Epoch [106/200], Train Loss: 0.0037967781800861385, Val Loss: 0.005259453610051423
Epoch [107/200], Train Loss: 0.0037818417344665663, Val Loss: 0.005259453610051423
Epoch [108/200], Train Loss: 0.0038005928085608916, Val Loss: 0.005259453610051423
Epoch [109/200], Train Loss: 0.003790328374386511, Val Loss: 0.005259453610051423
Epoch [110/200], Train Loss: 0.0037935613707469947, Val Loss: 0.005259453610051423
Epoch [111/200], Train Loss: 0.0037910646377978, Val Loss: 0.005259453610051423
Epoch [112/200], Train Loss: 0.003807278297079558, Val Loss: 0.005259453610051423
Epoch [113/200], Train Loss: 0.003806182283865796, Val Loss: 0.005259453610051423
Epoch [114/200], Train Loss: 0.003791727353183722, Val Loss: 0.005259453610051423
Epoch [115/200], Train Loss: 0.003797651257958602, Val Loss: 0.005259453610051423
Epoch [116/200], Train Loss: 0.003787062437781556, Val Loss: 0.005259453610051423
Epoch [117/200], Train Loss: 0.0037958658596670084, Val Loss: 0.005259453610051423
Epoch [118/200], Train Loss: 0.003801475564779883, Val Loss: 0.005259453610051423
Epoch [119/200], Train Loss: 0.0037969381717795677, Val Loss: 0.005259453610051423
Epoch [120/200], Train Loss: 0.0038085489491508765, Val Loss: 0.005259453610051423
Epoch [121/200], Train Loss: 0.003795599818907001, Val Loss: 0.005259453610051423
Epoch [122/200], Train Loss: 0.0037909776861356063, Val Loss: 0.005259453610051423
Epoch [123/200], Train Loss: 0.0037969710855660114, Val Loss: 0.005259453610051423
Epoch [124/200], Train Loss: 0.003796445078809153, Val Loss: 0.005259453610051423
Epoch [125/200], Train Loss: 0.0038100113160908222, Val Loss: 0.005259453610051423
Epoch [126/200], Train Loss: 0.0038042250406843696, Val Loss: 0.005259453610051423
Epoch [127/200], Train Loss: 0.0038002634061161766, Val Loss: 0.005259453610051423
Epoch [128/200], Train Loss: 0.00379640272479843, Val Loss: 0.005259453610051423
Epoch [129/200], Train Loss: 0.0037906996440142393, Val Loss: 0.005259453610051423
Epoch [130/200], Train Loss: 0.003802330180240626, Val Loss: 0.005259453610051423
Epoch [131/200], Train Loss: 0.0037956152016042984, Val Loss: 0.005259453610051423
Epoch [132/200], Train Loss: 0.0037900888816114853, Val Loss: 0.005259453610051423
Epoch [133/200], Train Loss: 0.0038023643534291873, Val Loss: 0.005259453610051423
Epoch [134/200], Train Loss: 0.0038008877414871345, Val Loss: 0.005259453610051423
Epoch [135/200], Train Loss: 0.0037997792771255427, Val Loss: 0.005259453610051423
Epoch [136/200], Train Loss: 0.0038070816081017256, Val Loss: 0.005259453610051423
Epoch [137/200], Train Loss: 0.0037970484488389707, Val Loss: 0.005259453610051423
Epoch [138/200], Train Loss: 0.0037929934174330397, Val Loss: 0.005259453610051423
Epoch [139/200], Train Loss: 0.003792756406421011, Val Loss: 0.005259453610051423
Epoch [140/200], Train Loss: 0.003796805087900297, Val Loss: 0.005259453610051423
Epoch [141/200], Train Loss: 0.0037961245980113745, Val Loss: 0.005259453610051423
Epoch [142/200], Train Loss: 0.0037992225049740887, Val Loss: 0.005259453610051423
Epoch [143/200], Train Loss: 0.003803005399690433, Val Loss: 0.005259453610051423
Epoch [144/200], Train Loss: 0.0037885620523328807, Val Loss: 0.005259453610051423
Epoch [145/200], Train Loss: 0.003790788998065347, Val Loss: 0.005259453610051423
Epoch [146/200], Train Loss: 0.00379016319162805, Val Loss: 0.005259453610051423
Epoch [147/200], Train Loss: 0.0037969157512469046, Val Loss: 0.005259453610051423
Epoch [148/200], Train Loss: 0.0037983340126546946, Val Loss: 0.005259453610051423
Epoch [149/200], Train Loss: 0.003789491612802852, Val Loss: 0.005259453610051423
Epoch [150/200], Train Loss: 0.003789667855016887, Val Loss: 0.005259453610051423
Epoch [151/200], Train Loss: 0.003792392767288468, Val Loss: 0.005259453610051423
Epoch [152/200], Train Loss: 0.0037875298452986913, Val Loss: 0.005259453610051423
Epoch [153/200], Train Loss: 0.0037972740299830384, Val Loss: 0.005259453610051423
Epoch [154/200], Train Loss: 0.0037938239455053754, Val Loss: 0.005259453610051423
Epoch [155/200], Train Loss: 0.003797071456739848, Val Loss: 0.005259453610051423
Epoch [156/200], Train Loss: 0.0037862523723478344, Val Loss: 0.005259453610051423
Epoch [157/200], Train Loss: 0.0037969119677489453, Val Loss: 0.005259453610051423
Epoch [158/200], Train Loss: 0.0037967218350703743, Val Loss: 0.005259453610051423
Epoch [159/200], Train Loss: 0.0037973882545801725, Val Loss: 0.005259453610051423
Epoch [160/200], Train Loss: 0.0037874848772348328, Val Loss: 0.005259453610051423
Epoch [161/200], Train Loss: 0.0037868640449067407, Val Loss: 0.005259453610051423
Epoch [162/200], Train Loss: 0.0037913904419507494, Val Loss: 0.005259453610051423
Epoch [163/200], Train Loss: 0.0037839794584380634, Val Loss: 0.005259453610051423
Epoch [164/200], Train Loss: 0.0037987714273516426, Val Loss: 0.005259453610051423
Epoch [165/200], Train Loss: 0.003790898206220432, Val Loss: 0.005259453610051423
Epoch [166/200], Train Loss: 0.0037884103049608793, Val Loss: 0.005259453610051423
Epoch [167/200], Train Loss: 0.003797520756382834, Val Loss: 0.005259453610051423
Epoch [168/200], Train Loss: 0.0037934359967369924, Val Loss: 0.005259453610051423
Epoch [169/200], Train Loss: 0.003790134479376403, Val Loss: 0.005259453610051423
Epoch [170/200], Train Loss: 0.0038040608633309603, Val Loss: 0.005259453610051423
Epoch [171/200], Train Loss: 0.0037938198180530558, Val Loss: 0.005259453610051423
Epoch [172/200], Train Loss: 0.003782027395738458, Val Loss: 0.005259453610051423
Epoch [173/200], Train Loss: 0.0037931498743339694, Val Loss: 0.005259453610051423
Epoch [174/200], Train Loss: 0.0038001058326864786, Val Loss: 0.005259453610051423
Epoch [175/200], Train Loss: 0.003781984999394891, Val Loss: 0.005259453610051423
Epoch [176/200], Train Loss: 0.00380077390846881, Val Loss: 0.005259453610051423
Epoch [177/200], Train Loss: 0.003795920601326295, Val Loss: 0.005259453610051423
Epoch [178/200], Train Loss: 0.0037893994330343876, Val Loss: 0.005259453610051423
Epoch [179/200], Train Loss: 0.0037919587339274585, Val Loss: 0.005259453610051423
Epoch [180/200], Train Loss: 0.003798113056373867, Val Loss: 0.005259453610051423
Epoch [181/200], Train Loss: 0.003787622871724042, Val Loss: 0.005259453610051423
Epoch [182/200], Train Loss: 0.0038026901046660814, Val Loss: 0.005259453610051423
Epoch [183/200], Train Loss: 0.0038030196870253844, Val Loss: 0.005259453610051423
Epoch [184/200], Train Loss: 0.0037885264345360074, Val Loss: 0.005259453610051423
Epoch [185/200], Train Loss: 0.0037869804655201733, Val Loss: 0.005259453610051423
Epoch [186/200], Train Loss: 0.003788010725243525, Val Loss: 0.005259453610051423
Epoch [187/200], Train Loss: 0.0038036021022972736, Val Loss: 0.005259453610051423
Epoch [188/200], Train Loss: 0.0038011421883394096, Val Loss: 0.005259453610051423
Epoch [189/200], Train Loss: 0.003797485620122064, Val Loss: 0.005259453610051423
Epoch [190/200], Train Loss: 0.0038018625187264247, Val Loss: 0.005259453610051423
Epoch [191/200], Train Loss: 0.0037862306132658637, Val Loss: 0.005259453610051423
Epoch [192/200], Train Loss: 0.003797875833697617, Val Loss: 0.005259453610051423
Epoch [193/200], Train Loss: 0.003794783747500994, Val Loss: 0.005259453610051423
Epoch [194/200], Train Loss: 0.003790485206991434, Val Loss: 0.005259453610051423
Epoch [195/200], Train Loss: 0.0037936603449369695, Val Loss: 0.005259453610051423
Epoch [196/200], Train Loss: 0.0037945885401727123, Val Loss: 0.005259453610051423
Epoch [197/200], Train Loss: 0.003803077757104554, Val Loss: 0.005259453610051423
Epoch [198/200], Train Loss: 0.003800053482832895, Val Loss: 0.005259453610051423
Epoch [199/200], Train Loss: 0.0037902860415422106, Val Loss: 0.005259453610051423
Epoch [200/200], Train Loss: 0.0037803066661581397, Val Loss: 0.005259453610051423
Testing w=0.01
Training and validation data loaded successfully on cuda.
Epoch [1/200], New best model saved with Val Loss: 0.0015784573915880173
Epoch [1/200], Train Loss: 0.001560760079883039, Val Loss: 0.0015784573915880173
Epoch [2/200], New best model saved with Val Loss: 0.0012319196393946186
Epoch [2/200], Train Loss: 0.0011806521215476096, Val Loss: 0.0012319196393946186
Epoch [3/200], Train Loss: 0.0011519943449953148, Val Loss: 0.0013464028888847679
Epoch [4/200], Train Loss: 0.001151659894358917, Val Loss: 0.001464003202272579
Epoch [5/200], New best model saved with Val Loss: 0.0011898955126525834
Epoch [5/200], Train Loss: 0.0013058013362090358, Val Loss: 0.0011898955126525834
Epoch [6/200], Train Loss: 0.0011796385806519538, Val Loss: 0.0012086546194041148
Epoch [7/200], New best model saved with Val Loss: 0.0011340255150571465
Epoch [7/200], Train Loss: 0.001223704216086348, Val Loss: 0.0011340255150571465
Epoch [8/200], New best model saved with Val Loss: 0.0011043723352486268
Epoch [8/200], Train Loss: 0.0011376207826701416, Val Loss: 0.0011043723352486268
Epoch [9/200], Train Loss: 0.0011364920183868062, Val Loss: 0.0015504342009080574
Epoch [10/200], Train Loss: 0.0011390451644811865, Val Loss: 0.001261044613784179
Epoch [11/200], Train Loss: 0.0011105855519417673, Val Loss: 0.001302644333918579
Epoch [12/200], Train Loss: 0.0011395670206349512, Val Loss: 0.0012723236286547035
Epoch [13/200], Train Loss: 0.0011467306030681357, Val Loss: 0.0011439047666499391
Epoch [14/200], Train Loss: 0.0011133082906863738, Val Loss: 0.0011188745265826583
Epoch [15/200], Train Loss: 0.001121177754777653, Val Loss: 0.0014590477076126263
Epoch [16/200], New best model saved with Val Loss: 0.0011032175971195102
Epoch [16/200], Train Loss: 0.001156978651785969, Val Loss: 0.0011032175971195102
Epoch [17/200], Train Loss: 0.0011610762336534788, Val Loss: 0.0012812862842110917
Epoch [18/200], Train Loss: 0.0011112720888129181, Val Loss: 0.0012177139287814498
Epoch [19/200], Train Loss: 0.0011026682662883434, Val Loss: 0.0013366130297072232
Epoch [20/200], Train Loss: 0.0011315454976283945, Val Loss: 0.0015224629605654627
Epoch [21/200], Train Loss: 0.0011075612035876309, Val Loss: 0.001241773323272355
Epoch [22/200], New best model saved with Val Loss: 0.0010739107528934255
Epoch [22/200], Train Loss: 0.0011217820323178205, Val Loss: 0.0010739107528934255
Epoch [23/200], Train Loss: 0.0011502521268663588, Val Loss: 0.001311049360083416
Epoch [24/200], Train Loss: 0.0011213245161343366, Val Loss: 0.0012362295819912106
Epoch [25/200], Train Loss: 0.0010969232958318157, Val Loss: 0.0011883301194757223
Epoch [26/200], Train Loss: 0.0011061534235275096, Val Loss: 0.001255338909686543
Epoch [27/200], Train Loss: 0.0011038905186896127, Val Loss: 0.00111727713374421
Epoch [28/200], Train Loss: 0.001098636227569924, Val Loss: 0.0012016813561785966
Epoch [29/200], New best model saved with Val Loss: 0.0010466002422617748
Epoch [29/200], Train Loss: 0.001092327041657303, Val Loss: 0.0010466002422617748
Epoch [30/200], Train Loss: 0.0011304645423396405, Val Loss: 0.0011766072420869023
Epoch [31/200], Train Loss: 0.001117815953462427, Val Loss: 0.001327709323959425
Epoch [32/200], Train Loss: 0.0011424920151264153, Val Loss: 0.0013801799359498546
Epoch [33/200], Train Loss: 0.0011281214498343286, Val Loss: 0.0012555409775814041
Epoch [34/200], Train Loss: 0.0011089647543320264, Val Loss: 0.0013609143352368847
Epoch [35/200], Train Loss: 0.001146756463144398, Val Loss: 0.0014986730238888413
Epoch [36/200], Train Loss: 0.0010633449869188057, Val Loss: 0.0010617720690788701
Epoch [37/200], Train Loss: 0.00113087611944965, Val Loss: 0.0011767059186240658
Epoch [38/200], Train Loss: 0.0011368029094724493, Val Loss: 0.0016487913962919265
Epoch [39/200], Train Loss: 0.0010968702832046388, Val Loss: 0.0010787671490106732
Epoch [40/200], Train Loss: 0.0011031134239270944, Val Loss: 0.0012686325935646892
Epoch [41/200], Train Loss: 0.0011316942995604636, Val Loss: 0.0012202365905977786
Epoch [42/200], Train Loss: 0.0010900420913292858, Val Loss: 0.0011936972732655704
Epoch [43/200], Train Loss: 0.0010958933377299797, Val Loss: 0.0010824641212821007
Epoch [44/200], Train Loss: 0.0010775133202762597, Val Loss: 0.0011670453532133251
Epoch [45/200], Train Loss: 0.0010789029838633724, Val Loss: 0.001218700417666696
Epoch [46/200], Train Loss: 0.0011231140564301643, Val Loss: 0.0014758695178898051
Epoch [47/200], New best model saved with Val Loss: 0.0010084156529046595
Epoch [47/200], Train Loss: 0.001060181064531207, Val Loss: 0.0010084156529046595
Epoch [48/200], Train Loss: 0.0011367746086431328, Val Loss: 0.001287057631998323
Epoch [49/200], Train Loss: 0.0010848014813249888, Val Loss: 0.001264015125343576
Epoch [50/200], Train Loss: 0.001089572108784606, Val Loss: 0.0012666146940318868
Epoch [51/200], Train Loss: 0.0010800065792864189, Val Loss: 0.0010352677054470405
Epoch [52/200], Train Loss: 0.0011146062123853799, Val Loss: 0.0010300336871296167
Epoch [53/200], Train Loss: 0.0010989376076560636, Val Loss: 0.0010987521382048726
Epoch [54/200], Train Loss: 0.0010742661966518922, Val Loss: 0.0010589353332761675
Epoch [55/200], Train Loss: 0.0010644445336021652, Val Loss: 0.0013688533217646182
Epoch [56/200], Train Loss: 0.001075712671577507, Val Loss: 0.0011653258989099413
Epoch [57/200], Train Loss: 0.0010754274381642144, Val Loss: 0.001196254655951634
Epoch [58/200], Train Loss: 0.0010564953739627856, Val Loss: 0.001165835332358256
Epoch [59/200], Train Loss: 0.0010612116649016652, Val Loss: 0.001193934804177843
Epoch [60/200], Train Loss: 0.0010689452458543449, Val Loss: 0.00117817975115031
Epoch [61/200], Train Loss: 0.0010681446305666627, Val Loss: 0.0012015405809506774
Epoch [62/200], Train Loss: 0.0010667680610574528, Val Loss: 0.001058560868841596
Epoch [63/200], Train Loss: 0.001047654485525775, Val Loss: 0.0012066652707289904
Epoch [64/200], Train Loss: 0.0010481481572655453, Val Loss: 0.0010466313688084483
Epoch [65/200], Train Loss: 0.0010639069805620238, Val Loss: 0.001127196752349846
Epoch [66/200], Train Loss: 0.0010544295265307565, Val Loss: 0.0011831495648948476
Epoch [67/200], Train Loss: 0.0010654221048091792, Val Loss: 0.0011281772021902725
Epoch [68/200], Train Loss: 0.0010551422971978106, Val Loss: 0.0011119067639810964
Epoch [69/200], Train Loss: 0.0010446815365205773, Val Loss: 0.0011249571980442852
Epoch [70/200], Train Loss: 0.001049471845776266, Val Loss: 0.0010084837558679283
Epoch [71/200], Train Loss: 0.0010626650480183096, Val Loss: 0.0012750737514579669
Epoch [72/200], Train Loss: 0.0010554709945360876, Val Loss: 0.0010533676977502182
Epoch [73/200], New best model saved with Val Loss: 0.0009277272765757516
Epoch [73/200], Train Loss: 0.0010664141445886344, Val Loss: 0.0009277272765757516
Epoch [74/200], Train Loss: 0.0010476608083329418, Val Loss: 0.0010842315823538229
Epoch [75/200], Train Loss: 0.001038605402837592, Val Loss: 0.001028318190947175
Epoch [76/200], Train Loss: 0.0010512329966083846, Val Loss: 0.0011513945064507425
Epoch [77/200], Train Loss: 0.0010539405663042669, Val Loss: 0.0011565153545234352
Epoch [78/200], Train Loss: 0.0010483852529432625, Val Loss: 0.0010792089015012607
Epoch [79/200], Train Loss: 0.0010468964756000787, Val Loss: 0.0011497566738398746
Epoch [80/200], Train Loss: 0.0010377140834779393, Val Loss: 0.0010353359102737159
Epoch [81/200], Train Loss: 0.0010411691040313929, Val Loss: 0.0010823963530128822
Epoch [82/200], Train Loss: 0.0010284087210576135, Val Loss: 0.0010444006038596854
Epoch [83/200], Train Loss: 0.0010303460201777687, Val Loss: 0.0009946269856300205
Epoch [84/200], Train Loss: 0.0010328227290301584, Val Loss: 0.0010355367994634435
Epoch [85/200], Train Loss: 0.0010260173942449248, Val Loss: 0.0011239311570534483
Epoch [86/200], Train Loss: 0.001029095849265683, Val Loss: 0.0010270772181684151
Epoch [87/200], Train Loss: 0.0010259430114687843, Val Loss: 0.000993122099316679
Epoch [88/200], Train Loss: 0.001051255817980167, Val Loss: 0.0009911465895129368
Epoch [89/200], Train Loss: 0.0010554428908190775, Val Loss: 0.0010901917412411422
Epoch [90/200], Train Loss: 0.001048258734623563, Val Loss: 0.0010097688209498301
Epoch [91/200], Train Loss: 0.0010497841133407994, Val Loss: 0.0009351216576760635
Epoch [92/200], Train Loss: 0.0010258184087102893, Val Loss: 0.001137666913564317
Epoch [93/200], Train Loss: 0.0010438820079963823, Val Loss: 0.0011114939698018134
Epoch [94/200], Train Loss: 0.0010354229690909217, Val Loss: 0.00105600556707941
Epoch [95/200], Train Loss: 0.001026912671064069, Val Loss: 0.0010583541734376922
Epoch [96/200], Train Loss: 0.0010257219725066204, Val Loss: 0.0009687469573691487
Epoch [97/200], Train Loss: 0.0010379165376600047, Val Loss: 0.0009863197337836027
Epoch [98/200], Train Loss: 0.0010302531696983021, Val Loss: 0.0010931565193459392
Epoch [99/200], Train Loss: 0.001047819954692386, Val Loss: 0.0010178687371080741
Epoch [100/200], Train Loss: 0.0010219229536067526, Val Loss: 0.0010111733281519264
Epoch [101/200], Train Loss: 0.001018088424726474, Val Loss: 0.0010628332529449835
Epoch [102/200], New best model saved with Val Loss: 0.0009140569891314954
Epoch [102/200], Train Loss: 0.0010198248306881976, Val Loss: 0.0009140569891314954
Epoch [103/200], Train Loss: 0.0010102631905200806, Val Loss: 0.0010370448144385591
Epoch [104/200], Train Loss: 0.001028970513619821, Val Loss: 0.0009992534323828295
Epoch [105/200], Train Loss: 0.0010252081013856116, Val Loss: 0.0009549507813062519
Epoch [106/200], Train Loss: 0.0010131018180717629, Val Loss: 0.0010045370872830972
Epoch [107/200], Train Loss: 0.001015445312739096, Val Loss: 0.0009914348920574412
Epoch [108/200], Train Loss: 0.0010138215306638317, Val Loss: 0.0010405313514638692
Epoch [109/200], Train Loss: 0.0010152398793831128, Val Loss: 0.0010139140649698675
Epoch [110/200], Train Loss: 0.001004371710719583, Val Loss: 0.0009766480652615428
Epoch [111/200], Train Loss: 0.0010132730246616782, Val Loss: 0.001028542304993607
Epoch [112/200], Train Loss: 0.0010115484963700344, Val Loss: 0.0010875416337512434
Epoch [113/200], Train Loss: 0.0010128555692393672, Val Loss: 0.0009749496093718335
Epoch [114/200], Train Loss: 0.001001742414452813, Val Loss: 0.0009919817675836384
Epoch [115/200], Train Loss: 0.001011786113270897, Val Loss: 0.0009819894330576062
Epoch [116/200], Train Loss: 0.0010023752256529406, Val Loss: 0.0010299402056261897
Epoch [117/200], Train Loss: 0.0010131298867318865, Val Loss: 0.001062015930074267
Epoch [118/200], Train Loss: 0.001011029059141451, Val Loss: 0.0010522784432396293
Epoch [119/200], Train Loss: 0.0010117280154107984, Val Loss: 0.001042200150550343
Epoch [120/200], Train Loss: 0.0010291127010449682, Val Loss: 0.00098528599482961
Epoch [121/200], Train Loss: 0.0010292764768978072, Val Loss: 0.0009892519447021186
Epoch [122/200], Train Loss: 0.00101037564242936, Val Loss: 0.00100992429361213
Epoch [123/200], Train Loss: 0.0010273412051240236, Val Loss: 0.001036700516124256
Epoch [124/200], Train Loss: 0.0010074405290652066, Val Loss: 0.0009909094806062058
Epoch [125/200], Train Loss: 0.001018722062739967, Val Loss: 0.0009853235096670687
Epoch [126/200], Train Loss: 0.0010215307120233774, Val Loss: 0.0010101293737534434
Epoch [127/200], Train Loss: 0.0010082875484262001, Val Loss: 0.001018093476886861
Epoch [128/200], Train Loss: 0.0010032361116662453, Val Loss: 0.0010221260163234547
Epoch [129/200], Train Loss: 0.001047183559752408, Val Loss: 0.0009240810977644287
Epoch [130/200], Train Loss: 0.00117575612437742, Val Loss: 0.0009404204465681687
Epoch [131/200], Train Loss: 0.001100880788395774, Val Loss: 0.0011549553310032934
Epoch [132/200], Train Loss: 0.0010069138807011768, Val Loss: 0.0009752550977282226
Epoch [133/200], Train Loss: 0.0010058930995662442, Val Loss: 0.000977905045147054
Epoch [134/200], Train Loss: 0.0010044084602585908, Val Loss: 0.0009846539032878354
Epoch [135/200], Train Loss: 0.0010078945508046838, Val Loss: 0.0010014201689045876
Epoch [136/200], Train Loss: 0.0010058423530691389, Val Loss: 0.0010219818796031177
Epoch [137/200], Train Loss: 0.0010014218026877973, Val Loss: 0.0010027450189227238
Epoch [138/200], Train Loss: 0.0010015798814658244, Val Loss: 0.0009977135923691094
Epoch [139/200], Train Loss: 0.0010022010742845437, Val Loss: 0.0009892394009511918
Epoch [140/200], Train Loss: 0.0010028261577562344, Val Loss: 0.0010063525551231578
Epoch [141/200], Train Loss: 0.0010043407885611734, Val Loss: 0.0009978567250072956
Epoch [142/200], Train Loss: 0.0010039037211258387, Val Loss: 0.0010027449752669781
Epoch [143/200], Train Loss: 0.0010089811760487712, Val Loss: 0.001006044534733519
Epoch [144/200], Train Loss: 0.0010059032197618349, Val Loss: 0.0010213413333985955
Epoch [145/200], Train Loss: 0.001009226208473344, Val Loss: 0.0009673417807789519
Epoch [146/200], Train Loss: 0.0010092365317342972, Val Loss: 0.000998531497316435
Epoch [147/200], Train Loss: 0.001004272693535313, Val Loss: 0.0009842312574619427
Epoch [148/200], Train Loss: 0.0010090478516014462, Val Loss: 0.001010268257232383
Epoch [149/200], Train Loss: 0.0010055019043978643, Val Loss: 0.000983848047326319
Epoch [150/200], Train Loss: 0.001007120394867591, Val Loss: 0.0009795002406463027
Epoch [151/200], Train Loss: 0.0010174190405946733, Val Loss: 0.0010229246108792722
Epoch [152/200], Train Loss: 0.0010090305546658453, Val Loss: 0.0009716781642055139
Epoch [153/200], Train Loss: 0.0010071914981711996, Val Loss: 0.0009931492386385798
Epoch [154/200], Train Loss: 0.0010026467180895534, Val Loss: 0.0010027572861872613
Epoch [155/200], Train Loss: 0.0010030625086404723, Val Loss: 0.000990382002783008
Epoch [156/200], Train Loss: 0.0010042812990088185, Val Loss: 0.0009716805652715266
Epoch [157/200], Train Loss: 0.001002912649710197, Val Loss: 0.0010036560706794262
Epoch [158/200], Train Loss: 0.0010054369605231013, Val Loss: 0.0009888542408589274
Epoch [159/200], Train Loss: 0.0010079135331166485, Val Loss: 0.0010125100961886346
Epoch [160/200], Train Loss: 0.0010001077038892122, Val Loss: 0.0009919563308358192
Epoch [161/200], Train Loss: 0.0010054046182300556, Val Loss: 0.0009777185186976567
Epoch [162/200], Train Loss: 0.0010062169974182987, Val Loss: 0.000983715828624554
Epoch [163/200], Train Loss: 0.0010047590926247226, Val Loss: 0.0010040198103524745
Epoch [164/200], Train Loss: 0.001004374609857967, Val Loss: 0.0010105569963343441
Epoch [165/200], Train Loss: 0.0010011572991391984, Val Loss: 0.0009824656299315393
Epoch [166/200], Train Loss: 0.0010049794185430403, Val Loss: 0.0009717067587189376
Epoch [167/200], Train Loss: 0.0010075091320851986, Val Loss: 0.0010066112299682572
Epoch [168/200], Train Loss: 0.0010045581663937562, Val Loss: 0.0009833824296947569
Epoch [169/200], Train Loss: 0.0010084429476674732, Val Loss: 0.0009805482986848801
Epoch [170/200], Train Loss: 0.0010063679140082306, Val Loss: 0.0009678519854787737
Epoch [171/200], Train Loss: 0.0010162062700890767, Val Loss: 0.0010150020098080859
Epoch [172/200], Train Loss: 0.0010066272284761494, Val Loss: 0.0009804008732317016
Epoch [173/200], Train Loss: 0.0009994811883767727, Val Loss: 0.000992601111647673
Epoch [174/200], Train Loss: 0.0010127689112612809, Val Loss: 0.0009838609403232113
Epoch [175/200], Train Loss: 0.0010017047845229338, Val Loss: 0.0009967324731405824
Epoch [176/200], Train Loss: 0.0010167798682232387, Val Loss: 0.0009771373734110966
Epoch [177/200], Train Loss: 0.0010050077345857228, Val Loss: 0.0010119046055478975
Epoch [178/200], Train Loss: 0.001008719324917448, Val Loss: 0.0009736336505739018
Epoch [179/200], Train Loss: 0.001004392609254203, Val Loss: 0.0010061787033919245
Epoch [180/200], Train Loss: 0.0010042803227075967, Val Loss: 0.0009910176013363525
Epoch [181/200], Train Loss: 0.0010064553472065281, Val Loss: 0.000997319701127708
Epoch [182/200], Train Loss: 0.0010005158679136498, Val Loss: 0.0010134411859326065
Epoch [183/200], Train Loss: 0.0010053358022229406, Val Loss: 0.0009858588164206594
Epoch [184/200], Train Loss: 0.0010062292038293724, Val Loss: 0.0009920297452481464
Epoch [185/200], Train Loss: 0.001007155450431376, Val Loss: 0.001006269987556152
Epoch [186/200], Train Loss: 0.001004652314639481, Val Loss: 0.0009912984678521752
Epoch [187/200], Train Loss: 0.0010036589638647538, Val Loss: 0.0009914048860082403
Epoch [188/200], Train Loss: 0.001000547003720633, Val Loss: 0.000989287902484648
Epoch [189/200], Train Loss: 0.0010103322472952475, Val Loss: 0.0009907646308420226
Epoch [190/200], Train Loss: 0.0010021660127677023, Val Loss: 0.0010072868171846494
Epoch [191/200], Train Loss: 0.0010093926843679087, Val Loss: 0.0009817336249398068
Epoch [192/200], Train Loss: 0.001005119348436975, Val Loss: 0.0010079110215883702
Epoch [193/200], Train Loss: 0.0010101664348357272, Val Loss: 0.000980176409939304
Epoch [194/200], Train Loss: 0.00100681660577803, Val Loss: 0.0009858404810074717
Epoch [195/200], Train Loss: 0.0010057327348146248, Val Loss: 0.0010079564817715436
Epoch [196/200], Train Loss: 0.0010151896144221114, Val Loss: 0.000983877238468267
Epoch [197/200], Train Loss: 0.0010162738379387354, Val Loss: 0.000995365291601047
Epoch [198/200], Train Loss: 0.0010076781618408859, Val Loss: 0.000990098953479901
Epoch [199/200], Train Loss: 0.001004704405204393, Val Loss: 0.0009956499125109985
Epoch [200/200], Train Loss: 0.0010050215873475695, Val Loss: 0.0010037618922069669
Testing w=0.02
Training and validation data loaded successfully on cuda.
Epoch [1/200], New best model saved with Val Loss: 0.0016003265336621553
Epoch [1/200], Train Loss: 0.0015192015509290452, Val Loss: 0.0016003265336621553
Epoch [2/200], New best model saved with Val Loss: 0.001489752350607887
Epoch [2/200], Train Loss: 0.0016548642677000978, Val Loss: 0.001489752350607887
Epoch [3/200], New best model saved with Val Loss: 0.0014623200986534357
Epoch [3/200], Train Loss: 0.0016083305156578056, Val Loss: 0.0014623200986534357
Epoch [4/200], New best model saved with Val Loss: 0.0014568788465112448
Epoch [4/200], Train Loss: 0.0015946049719456244, Val Loss: 0.0014568788465112448
Epoch [5/200], New best model saved with Val Loss: 0.0014543256256729364
Epoch [5/200], Train Loss: 0.0015868519972586496, Val Loss: 0.0014543256256729364
Epoch [6/200], Train Loss: 0.0015917463302188976, Val Loss: 0.001457880571251735
Epoch [7/200], Train Loss: 0.001585784818003462, Val Loss: 0.0014559587289113551
Epoch [8/200], Train Loss: 0.0015965929911048574, Val Loss: 0.0014609578647650778
Epoch [9/200], Train Loss: 0.0015918944422578948, Val Loss: 0.0014634537510573864
Epoch [10/200], Train Loss: 0.0015930916468443518, Val Loss: 0.0014613444218412042
Epoch [11/200], Train Loss: 0.0015942803901535544, Val Loss: 0.0014604355092160404
Epoch [12/200], Train Loss: 0.0015924093075392937, Val Loss: 0.001459906721720472
Epoch [13/200], Train Loss: 0.0015945974525741556, Val Loss: 0.0014615019608754665
Epoch [14/200], Train Loss: 0.0015953618990765376, Val Loss: 0.0014576650282833725
Epoch [15/200], Train Loss: 0.0016020706309725276, Val Loss: 0.0014605756441596895
Epoch [16/200], Train Loss: 0.0015932196798861366, Val Loss: 0.001456356403650716
Epoch [17/200], Train Loss: 0.00159427872329781, Val Loss: 0.0014605014584958553
Epoch [18/200], Train Loss: 0.0015918743394484575, Val Loss: 0.0014626348274759948
Epoch [19/200], Train Loss: 0.0015937168235805902, Val Loss: 0.0014590542996302247
Epoch [20/200], Train Loss: 0.0015918652193663133, Val Loss: 0.0014546420716214925
Epoch [21/200], New best model saved with Val Loss: 0.0014526966551784426
Epoch [21/200], Train Loss: 0.0015939439869147134, Val Loss: 0.0014526966551784426
Epoch [22/200], New best model saved with Val Loss: 0.0014489495079033077
Epoch [22/200], Train Loss: 0.0015905833199874244, Val Loss: 0.0014489495079033077
Epoch [23/200], New best model saved with Val Loss: 0.0014467387227341533
Epoch [23/200], Train Loss: 0.0015995081048458815, Val Loss: 0.0014467387227341533
Epoch [24/200], New best model saved with Val Loss: 0.0014373534941114485
Epoch [24/200], Train Loss: 0.0015915545941838486, Val Loss: 0.0014373534941114485
Epoch [25/200], Train Loss: 0.0015954175429545683, Val Loss: 0.0014803324011154473
Epoch [26/200], Train Loss: 0.001608012588059699, Val Loss: 0.001476657489547506
Epoch [27/200], Train Loss: 0.0016218468874946914, Val Loss: 0.0014745274966116995
Epoch [28/200], Train Loss: 0.0016075470061464744, Val Loss: 0.0014968058676458895
Epoch [29/200], Train Loss: 0.0016019145577129993, Val Loss: 0.0014716168807353824
Epoch [30/200], Train Loss: 0.0015918857164003632, Val Loss: 0.00151784997433424
Epoch [31/200], Train Loss: 0.0015816983147735962, Val Loss: 0.0015217628970276564
Epoch [32/200], Train Loss: 0.0015760154505683618, Val Loss: 0.0015214764571283013
Epoch [33/200], Train Loss: 0.00153686029212126, Val Loss: 0.0015152247215155512
Epoch [34/200], Train Loss: 0.0015350453507959503, Val Loss: 0.0014879867667332292
Epoch [35/200], New best model saved with Val Loss: 0.001423343928763643
Epoch [35/200], Train Loss: 0.0015282060379501093, Val Loss: 0.001423343928763643
Epoch [36/200], Train Loss: 0.0015361521483017978, Val Loss: 0.0014465853455476463
Epoch [37/200], Train Loss: 0.0015484523874792185, Val Loss: 0.0014264233177527785
Epoch [38/200], New best model saved with Val Loss: 0.0013767456403002143
Epoch [38/200], Train Loss: 0.0015636965426066044, Val Loss: 0.0013767456403002143
Epoch [39/200], New best model saved with Val Loss: 0.0013438679743558168
Epoch [39/200], Train Loss: 0.0015584224443459375, Val Loss: 0.0013438679743558168
Epoch [40/200], New best model saved with Val Loss: 0.0012809809413738549
Epoch [40/200], Train Loss: 0.0015751848695799708, Val Loss: 0.0012809809413738549
Epoch [41/200], New best model saved with Val Loss: 0.0012375435617286712
Epoch [41/200], Train Loss: 0.0015968265943229198, Val Loss: 0.0012375435617286712
Epoch [42/200], Train Loss: 0.0015964689108924094, Val Loss: 0.0012493848334997892
Epoch [43/200], New best model saved with Val Loss: 0.0012282767711440101
Epoch [43/200], Train Loss: 0.0015868373077616773, Val Loss: 0.0012282767711440101
Traceback (most recent call last):
  File "/blue/guo/yangh/Toy_PEDS/search_weight.py", line 62, in <module>
    train_losses, val_losses=dm.fit(params=params,learning_rate=0.1,save_path=weight_path)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/Toy_PEDS/DiffusionModel.py", line 90, in fit
    pred = self(x_batch,params)
           ^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/.conda/envs/PEDS/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/.conda/envs/PEDS/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/Toy_PEDS/DiffusionModel.py", line 60, in forward
    x = LF_Layer.apply(final_D, params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/.conda/envs/PEDS/lib/python3.12/site-packages/torch/autograd/function.py", line 574, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/Toy_PEDS/LF_1D.py", line 19, in forward
    U = fd.solve(N=N, D=D, plot=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/Toy_PEDS/FD_1D.py", line 59, in solve
    u=np.linalg.inv(A)@b
      ^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/.conda/envs/PEDS/lib/python3.12/site-packages/numpy/linalg/_linalg.py", line 615, in inv
    ainv = _umath_linalg.inv(a, signature=signature)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/blue/guo/yangh/.conda/envs/PEDS/lib/python3.12/site-packages/numpy/linalg/_linalg.py", line 104, in _raise_linalgerror_singular
    raise LinAlgError("Singular matrix")
numpy.linalg.LinAlgError: Singular matrix
